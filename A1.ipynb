{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFzd\n"
     ]
    }
   ],
   "source": [
    "print(\"SFzd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.67.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.1-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
      "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/385.0 MB 4.2 MB/s eta 0:01:33\n",
      "   ---------------------------------------- 1.8/385.0 MB 5.6 MB/s eta 0:01:09\n",
      "   ---------------------------------------- 3.4/385.0 MB 6.5 MB/s eta 0:00:59\n",
      "   ---------------------------------------- 4.7/385.0 MB 6.3 MB/s eta 0:01:00\n",
      "   ---------------------------------------- 4.7/385.0 MB 6.3 MB/s eta 0:01:00\n",
      "    --------------------------------------- 6.8/385.0 MB 5.7 MB/s eta 0:01:07\n",
      "    --------------------------------------- 7.9/385.0 MB 5.8 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 9.7/385.0 MB 6.0 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 10.5/385.0 MB 5.7 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 10.5/385.0 MB 5.7 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 11.8/385.0 MB 5.2 MB/s eta 0:01:12\n",
      "   - -------------------------------------- 13.9/385.0 MB 5.6 MB/s eta 0:01:07\n",
      "   - -------------------------------------- 15.7/385.0 MB 5.9 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 17.6/385.0 MB 6.0 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 19.9/385.0 MB 6.4 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 22.0/385.0 MB 6.6 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 24.4/385.0 MB 6.9 MB/s eta 0:00:53\n",
      "   -- ------------------------------------- 26.0/385.0 MB 6.9 MB/s eta 0:00:52\n",
      "   -- ------------------------------------- 27.8/385.0 MB 7.1 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 30.4/385.0 MB 7.3 MB/s eta 0:00:49\n",
      "   --- ------------------------------------ 33.3/385.0 MB 7.6 MB/s eta 0:00:47\n",
      "   --- ------------------------------------ 34.9/385.0 MB 7.7 MB/s eta 0:00:46\n",
      "   --- ------------------------------------ 36.4/385.0 MB 7.6 MB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 38.8/385.0 MB 7.8 MB/s eta 0:00:45\n",
      "   ---- ----------------------------------- 40.1/385.0 MB 7.8 MB/s eta 0:00:45\n",
      "   ---- ----------------------------------- 40.6/385.0 MB 7.7 MB/s eta 0:00:45\n",
      "   ---- ----------------------------------- 43.8/385.0 MB 7.8 MB/s eta 0:00:44\n",
      "   ---- ----------------------------------- 44.8/385.0 MB 7.8 MB/s eta 0:00:44\n",
      "   ---- ----------------------------------- 45.9/385.0 MB 7.6 MB/s eta 0:00:45\n",
      "   ---- ----------------------------------- 46.1/385.0 MB 7.5 MB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 46.7/385.0 MB 7.3 MB/s eta 0:00:47\n",
      "   ---- ----------------------------------- 47.2/385.0 MB 7.1 MB/s eta 0:00:48\n",
      "   ---- ----------------------------------- 48.0/385.0 MB 7.0 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 48.8/385.0 MB 6.9 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 49.8/385.0 MB 6.8 MB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 50.9/385.0 MB 6.8 MB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 51.9/385.0 MB 6.8 MB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 53.2/385.0 MB 6.7 MB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 54.8/385.0 MB 6.7 MB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 55.8/385.0 MB 6.7 MB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 57.4/385.0 MB 6.7 MB/s eta 0:00:49\n",
      "   ------ --------------------------------- 58.2/385.0 MB 6.6 MB/s eta 0:00:50\n",
      "   ------ --------------------------------- 59.5/385.0 MB 6.6 MB/s eta 0:00:50\n",
      "   ------ --------------------------------- 61.1/385.0 MB 6.6 MB/s eta 0:00:49\n",
      "   ------ --------------------------------- 62.7/385.0 MB 6.7 MB/s eta 0:00:49\n",
      "   ------ --------------------------------- 64.7/385.0 MB 6.7 MB/s eta 0:00:48\n",
      "   ------ --------------------------------- 67.1/385.0 MB 6.8 MB/s eta 0:00:47\n",
      "   ------- -------------------------------- 69.5/385.0 MB 6.9 MB/s eta 0:00:46\n",
      "   ------- -------------------------------- 71.8/385.0 MB 7.0 MB/s eta 0:00:45\n",
      "   ------- -------------------------------- 74.4/385.0 MB 7.1 MB/s eta 0:00:44\n",
      "   ------- -------------------------------- 76.8/385.0 MB 7.2 MB/s eta 0:00:43\n",
      "   -------- ------------------------------- 79.7/385.0 MB 7.3 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 82.6/385.0 MB 7.4 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 85.7/385.0 MB 7.6 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 88.3/385.0 MB 7.7 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 91.5/385.0 MB 7.8 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 93.6/385.0 MB 7.9 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 95.2/385.0 MB 7.8 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 97.0/385.0 MB 7.9 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 98.3/385.0 MB 7.8 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 100.7/385.0 MB 7.9 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 101.4/385.0 MB 7.8 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 104.1/385.0 MB 7.9 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 105.4/385.0 MB 7.8 MB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 105.9/385.0 MB 7.9 MB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 105.9/385.0 MB 7.9 MB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 108.5/385.0 MB 7.7 MB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 110.1/385.0 MB 7.7 MB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 112.2/385.0 MB 7.8 MB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 114.6/385.0 MB 7.8 MB/s eta 0:00:35\n",
      "   ------------ --------------------------- 116.7/385.0 MB 7.8 MB/s eta 0:00:35\n",
      "   ------------ --------------------------- 119.3/385.0 MB 7.9 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 120.6/385.0 MB 7.9 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 122.7/385.0 MB 7.9 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 126.1/385.0 MB 8.0 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 128.5/385.0 MB 8.1 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 131.3/385.0 MB 8.2 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 132.4/385.0 MB 8.1 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 132.4/385.0 MB 8.1 MB/s eta 0:00:32\n",
      "   -------------- ------------------------- 135.8/385.0 MB 8.1 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 137.9/385.0 MB 8.1 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 140.2/385.0 MB 8.2 MB/s eta 0:00:30\n",
      "   -------------- ------------------------- 142.9/385.0 MB 8.2 MB/s eta 0:00:30\n",
      "   --------------- ------------------------ 145.2/385.0 MB 8.3 MB/s eta 0:00:30\n",
      "   --------------- ------------------------ 147.8/385.0 MB 8.3 MB/s eta 0:00:29\n",
      "   --------------- ------------------------ 150.7/385.0 MB 8.4 MB/s eta 0:00:29\n",
      "   --------------- ------------------------ 153.4/385.0 MB 8.4 MB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 156.2/385.0 MB 8.5 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 158.9/385.0 MB 8.5 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 159.4/385.0 MB 8.5 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 162.3/385.0 MB 8.5 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 162.3/385.0 MB 8.5 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 167.0/385.0 MB 8.6 MB/s eta 0:00:26\n",
      "   ----------------- ---------------------- 170.1/385.0 MB 8.6 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 173.8/385.0 MB 8.7 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 176.7/385.0 MB 8.8 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 178.8/385.0 MB 8.8 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 181.4/385.0 MB 8.8 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 183.2/385.0 MB 8.8 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 185.9/385.0 MB 8.9 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 187.7/385.0 MB 8.9 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 189.5/385.0 MB 8.9 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 191.6/385.0 MB 8.9 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 194.0/385.0 MB 8.9 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 195.8/385.0 MB 8.9 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 197.7/385.0 MB 8.9 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 199.5/385.0 MB 8.9 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 201.1/385.0 MB 8.9 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 203.2/385.0 MB 8.9 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 205.0/385.0 MB 8.9 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 206.3/385.0 MB 8.9 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 208.1/385.0 MB 8.8 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 210.0/385.0 MB 8.8 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 211.0/385.0 MB 8.8 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 211.8/385.0 MB 8.8 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 211.8/385.0 MB 8.8 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 212.6/385.0 MB 8.7 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 215.2/385.0 MB 8.7 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 218.9/385.0 MB 8.8 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 220.5/385.0 MB 8.8 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 221.0/385.0 MB 8.7 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 224.9/385.0 MB 8.8 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 227.5/385.0 MB 8.8 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 229.6/385.0 MB 8.8 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 233.0/385.0 MB 8.9 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 235.7/385.0 MB 8.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 239.3/385.0 MB 9.0 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 242.7/385.0 MB 9.0 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 243.5/385.0 MB 9.0 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 243.5/385.0 MB 9.0 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 245.6/385.0 MB 8.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 246.4/385.0 MB 8.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 246.4/385.0 MB 8.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 247.7/385.0 MB 8.8 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 249.8/385.0 MB 8.8 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 252.2/385.0 MB 8.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 253.5/385.0 MB 8.8 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 255.9/385.0 MB 8.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 259.8/385.0 MB 8.9 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 260.0/385.0 MB 8.9 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 261.4/385.0 MB 8.8 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 265.0/385.0 MB 8.9 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 265.0/385.0 MB 8.9 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 266.3/385.0 MB 8.9 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 268.4/385.0 MB 9.0 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 268.4/385.0 MB 9.0 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 270.3/385.0 MB 8.9 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 273.4/385.0 MB 9.0 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 275.8/385.0 MB 9.1 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 278.1/385.0 MB 9.1 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 282.9/385.0 MB 9.2 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 286.8/385.0 MB 9.2 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 289.4/385.0 MB 9.2 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 290.5/385.0 MB 9.2 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 290.5/385.0 MB 9.2 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 295.2/385.0 MB 9.2 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 296.0/385.0 MB 9.2 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 297.5/385.0 MB 9.1 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 298.8/385.0 MB 9.1 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 300.9/385.0 MB 9.1 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 306.7/385.0 MB 9.3 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 309.1/385.0 MB 9.5 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 313.3/385.0 MB 9.8 MB/s eta 0:00:08\n",
      "   -------------------------------- ------ 318.0/385.0 MB 10.0 MB/s eta 0:00:07\n",
      "   -------------------------------- ------ 319.8/385.0 MB 10.0 MB/s eta 0:00:07\n",
      "   -------------------------------- ------ 320.1/385.0 MB 10.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------ 320.1/385.0 MB 10.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 321.4/385.0 MB 9.9 MB/s eta 0:00:07\n",
      "   -------------------------------- ------ 325.6/385.0 MB 10.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 325.6/385.0 MB 10.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 326.9/385.0 MB 9.9 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 326.9/385.0 MB 9.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 327.9/385.0 MB 9.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 329.5/385.0 MB 9.8 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 329.8/385.0 MB 9.7 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 330.0/385.0 MB 9.7 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 330.0/385.0 MB 9.7 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 332.7/385.0 MB 9.6 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 332.9/385.0 MB 9.5 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 334.5/385.0 MB 9.5 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 335.3/385.0 MB 9.4 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 336.3/385.0 MB 9.4 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 336.9/385.0 MB 9.3 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 337.1/385.0 MB 9.3 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 337.1/385.0 MB 9.3 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 338.7/385.0 MB 9.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 339.2/385.0 MB 9.1 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 341.0/385.0 MB 9.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 342.4/385.0 MB 9.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 343.4/385.0 MB 9.0 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 344.5/385.0 MB 9.0 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 346.0/385.0 MB 8.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 346.8/385.0 MB 8.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 348.1/385.0 MB 8.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 349.2/385.0 MB 8.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 349.4/385.0 MB 8.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 350.0/385.0 MB 8.7 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 350.5/385.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 350.5/385.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 350.7/385.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 350.7/385.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 350.7/385.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 350.7/385.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 351.0/385.0 MB 8.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 352.8/385.0 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 354.4/385.0 MB 8.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 356.0/385.0 MB 8.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 356.8/385.0 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 357.0/385.0 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 358.1/385.0 MB 8.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 358.4/385.0 MB 8.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 359.1/385.0 MB 8.1 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 359.1/385.0 MB 8.1 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 359.9/385.0 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 359.9/385.0 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 360.4/385.0 MB 7.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 362.5/385.0 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 364.1/385.0 MB 7.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 366.0/385.0 MB 7.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 366.5/385.0 MB 7.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 366.5/385.0 MB 7.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 368.1/385.0 MB 7.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 369.4/385.0 MB 7.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 370.1/385.0 MB 7.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 370.9/385.0 MB 7.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 372.5/385.0 MB 7.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 374.3/385.0 MB 7.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  376.2/385.0 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  377.5/385.0 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  377.7/385.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  377.7/385.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  379.8/385.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  380.4/385.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  380.9/385.0 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  381.7/385.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  382.5/385.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.3/385.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 385.0/385.0 MB 6.6 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.0-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.8/4.4 MB 931.2 kB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.0/4.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 1.8/4.4 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.1/4.4 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.1/4.4 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.1/4.4 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.4/4.4 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.4/4.4 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.6/4.4 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.9/4.4 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.9/4.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 3.1/4.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 3.1/4.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.4/4.4 MB 949.5 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.7/4.4 MB 956.5 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.7/4.4 MB 956.5 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.7/4.4 MB 956.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.4 MB 942.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.4 MB 942.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 896.4 kB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.5/3.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.5/3.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.5/3.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.5/3.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.8/3.0 MB 435.8 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 0.8/3.0 MB 435.8 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 0.8/3.0 MB 435.8 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 1.0/3.0 MB 433.8 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 1.3/3.0 MB 508.3 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 1.3/3.0 MB 508.3 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.6/3.0 MB 521.0 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 1.8/3.0 MB 588.6 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 2.1/3.0 MB 638.3 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 2.4/3.0 MB 681.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.9/3.0 MB 769.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 784.0 kB/s eta 0:00:00\n",
      "Using cached keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.0/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.6/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 2.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.9/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.4/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.9/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.5/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.0/15.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 7.3/15.8 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 8.1/15.8 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 9.7/15.8 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 10.0/15.8 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 10.0/15.8 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 10.2/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.5/15.8 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.5/15.8 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 11.0/15.8 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.8/15.8 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.1/15.8 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.1/15.8 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.1/15.8 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.8/15.8 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.4/15.8 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 14.2/15.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 2.1 MB/s eta 0:00:00\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.0/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.6 MB/s eta 0:00:00\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Using cached wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp311-cp311-win_amd64.whl (283 kB)\n",
      "Using cached rich-13.9.2-py3-none-any.whl (242 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.1-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, absl-py, werkzeug, requests, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed MarkupSafe-3.0.1 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.8.30 charset-normalizer-3.4.0 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.0 h5py-3.12.1 idna-3.10 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-1.26.4 opt-einsum-3.4.0 optree-0.13.0 protobuf-4.25.5 requests-2.32.3 rich-13.9.2 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 urllib3-2.2.3 werkzeug-3.0.4 wheel-0.44.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mlxtend 0.23.0 requires joblib>=0.13.2, which is not installed.\n",
      "mlxtend 0.23.0 requires matplotlib>=3.0.0, which is not installed.\n",
      "mlxtend 0.23.0 requires pandas>=0.24.2, which is not installed.\n",
      "mlxtend 0.23.0 requires scikit-learn>=1.0.2, which is not installed.\n",
      "mlxtend 0.23.0 requires scipy>=1.2.1, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loadtxt('diabetes.csv', delimiter=',', skiprows=1)\n",
    "x = dataset[:, 0:8]  # Features\n",
    "y = dataset[:, 8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5373 - loss: 7.4007\n",
      "Epoch 2/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6505 - loss: 1.7752\n",
      "Epoch 3/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6476 - loss: 1.2494\n",
      "Epoch 4/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6460 - loss: 0.9422\n",
      "Epoch 5/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6651 - loss: 0.8070\n",
      "Epoch 6/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6508 - loss: 0.7874\n",
      "Epoch 7/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6465 - loss: 0.7154\n",
      "Epoch 8/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6667 - loss: 0.6975\n",
      "Epoch 9/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6812 - loss: 0.6454\n",
      "Epoch 10/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6608 - loss: 0.7245\n",
      "Epoch 11/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6450 - loss: 0.6561\n",
      "Epoch 12/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6583 - loss: 0.6923\n",
      "Epoch 13/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6833 - loss: 0.6483\n",
      "Epoch 14/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6422 - loss: 0.6683\n",
      "Epoch 15/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6828 - loss: 0.6191\n",
      "Epoch 16/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6475 - loss: 0.6390\n",
      "Epoch 17/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7055 - loss: 0.5997\n",
      "Epoch 18/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6656 - loss: 0.6507\n",
      "Epoch 19/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.5903\n",
      "Epoch 20/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6648 - loss: 0.6252\n",
      "Epoch 21/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7037 - loss: 0.5845\n",
      "Epoch 22/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.6071\n",
      "Epoch 23/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7017 - loss: 0.5731\n",
      "Epoch 24/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6706 - loss: 0.6269\n",
      "Epoch 25/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7130 - loss: 0.5629\n",
      "Epoch 26/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6883 - loss: 0.5912\n",
      "Epoch 27/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.5431\n",
      "Epoch 28/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.5764\n",
      "Epoch 29/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7331 - loss: 0.5591\n",
      "Epoch 30/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6716 - loss: 0.6069\n",
      "Epoch 31/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.5715\n",
      "Epoch 32/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.5909\n",
      "Epoch 33/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7198 - loss: 0.5749\n",
      "Epoch 34/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6887 - loss: 0.5837\n",
      "Epoch 35/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.5796\n",
      "Epoch 36/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7159 - loss: 0.5426\n",
      "Epoch 37/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7064 - loss: 0.5722\n",
      "Epoch 38/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7294 - loss: 0.5556\n",
      "Epoch 39/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6966 - loss: 0.5732\n",
      "Epoch 40/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.5784\n",
      "Epoch 41/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6873 - loss: 0.5659\n",
      "Epoch 42/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 0.5665\n",
      "Epoch 43/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7072 - loss: 0.5668\n",
      "Epoch 44/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7642 - loss: 0.5121\n",
      "Epoch 45/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.5635\n",
      "Epoch 46/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7558 - loss: 0.4872\n",
      "Epoch 47/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7175 - loss: 0.5401\n",
      "Epoch 48/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5227\n",
      "Epoch 49/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.5426\n",
      "Epoch 50/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.5455\n",
      "Epoch 51/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7258 - loss: 0.5465\n",
      "Epoch 52/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7066 - loss: 0.5680\n",
      "Epoch 53/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.5523\n",
      "Epoch 54/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7587 - loss: 0.5100\n",
      "Epoch 55/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7085 - loss: 0.5521\n",
      "Epoch 56/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7508 - loss: 0.5124\n",
      "Epoch 57/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7687 - loss: 0.5153\n",
      "Epoch 58/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5289\n",
      "Epoch 59/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7689 - loss: 0.5155\n",
      "Epoch 60/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6957 - loss: 0.5285\n",
      "Epoch 61/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.5158\n",
      "Epoch 62/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7185 - loss: 0.5391\n",
      "Epoch 63/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7292 - loss: 0.5418\n",
      "Epoch 64/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5378\n",
      "Epoch 65/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7521 - loss: 0.4948\n",
      "Epoch 66/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7462 - loss: 0.5180\n",
      "Epoch 67/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.5113\n",
      "Epoch 68/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7452 - loss: 0.5303\n",
      "Epoch 69/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7297 - loss: 0.5102\n",
      "Epoch 70/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.5451\n",
      "Epoch 71/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.5347\n",
      "Epoch 72/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7303 - loss: 0.5216\n",
      "Epoch 73/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7010 - loss: 0.5451\n",
      "Epoch 74/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7343 - loss: 0.5158\n",
      "Epoch 75/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7691 - loss: 0.4984\n",
      "Epoch 76/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7534 - loss: 0.5330\n",
      "Epoch 77/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7482 - loss: 0.5235\n",
      "Epoch 78/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7088 - loss: 0.5229\n",
      "Epoch 79/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7428 - loss: 0.5244\n",
      "Epoch 80/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7202 - loss: 0.5518\n",
      "Epoch 81/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7616 - loss: 0.4989\n",
      "Epoch 82/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7306 - loss: 0.5090\n",
      "Epoch 83/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.5474\n",
      "Epoch 84/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7505 - loss: 0.4991\n",
      "Epoch 85/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7727 - loss: 0.4989\n",
      "Epoch 86/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7282 - loss: 0.5350\n",
      "Epoch 87/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7452 - loss: 0.5201\n",
      "Epoch 88/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7162 - loss: 0.5407\n",
      "Epoch 89/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7452 - loss: 0.5206\n",
      "Epoch 90/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7156 - loss: 0.5396\n",
      "Epoch 91/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.5249\n",
      "Epoch 92/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7283 - loss: 0.5301\n",
      "Epoch 93/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7411 - loss: 0.4930\n",
      "Epoch 94/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7598 - loss: 0.4932\n",
      "Epoch 95/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7338 - loss: 0.5126\n",
      "Epoch 96/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7305 - loss: 0.5374\n",
      "Epoch 97/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7749 - loss: 0.4962\n",
      "Epoch 98/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7420 - loss: 0.5029\n",
      "Epoch 99/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7682 - loss: 0.4897\n",
      "Epoch 100/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5330\n",
      "Epoch 101/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7420 - loss: 0.5185\n",
      "Epoch 102/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7552 - loss: 0.4955\n",
      "Epoch 103/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7665 - loss: 0.4789\n",
      "Epoch 104/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7415 - loss: 0.5189\n",
      "Epoch 105/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7570 - loss: 0.4897\n",
      "Epoch 106/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.4785\n",
      "Epoch 107/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7881 - loss: 0.4852\n",
      "Epoch 108/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7883 - loss: 0.4686\n",
      "Epoch 109/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7623 - loss: 0.4908\n",
      "Epoch 110/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.4637\n",
      "Epoch 111/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7762 - loss: 0.4848\n",
      "Epoch 112/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7560 - loss: 0.4749\n",
      "Epoch 113/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7791 - loss: 0.4734\n",
      "Epoch 114/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7029 - loss: 0.5236\n",
      "Epoch 115/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7693 - loss: 0.4841\n",
      "Epoch 116/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7555 - loss: 0.5060\n",
      "Epoch 117/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7572 - loss: 0.4999\n",
      "Epoch 118/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7446 - loss: 0.5169\n",
      "Epoch 119/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.5218\n",
      "Epoch 120/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7619 - loss: 0.4969\n",
      "Epoch 121/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7631 - loss: 0.4902\n",
      "Epoch 122/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7739 - loss: 0.4849\n",
      "Epoch 123/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7632 - loss: 0.4852\n",
      "Epoch 124/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7360 - loss: 0.5000\n",
      "Epoch 125/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7577 - loss: 0.4837\n",
      "Epoch 126/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7989 - loss: 0.4763\n",
      "Epoch 127/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7491 - loss: 0.5038\n",
      "Epoch 128/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7682 - loss: 0.4617\n",
      "Epoch 129/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.5037\n",
      "Epoch 130/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.5250\n",
      "Epoch 131/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7707 - loss: 0.4801\n",
      "Epoch 132/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7664 - loss: 0.4693\n",
      "Epoch 133/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.5220\n",
      "Epoch 134/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7175 - loss: 0.5292\n",
      "Epoch 135/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7518 - loss: 0.4911\n",
      "Epoch 136/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7575 - loss: 0.4968\n",
      "Epoch 137/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.4865\n",
      "Epoch 138/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.4846\n",
      "Epoch 139/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7548 - loss: 0.4762\n",
      "Epoch 140/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7727 - loss: 0.4868\n",
      "Epoch 141/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7758 - loss: 0.4753\n",
      "Epoch 142/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7872 - loss: 0.4532\n",
      "Epoch 143/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7580 - loss: 0.4866\n",
      "Epoch 144/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5193\n",
      "Epoch 145/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7576 - loss: 0.5071\n",
      "Epoch 146/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7417 - loss: 0.4875\n",
      "Epoch 147/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7564 - loss: 0.5057\n",
      "Epoch 148/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7882 - loss: 0.4665\n",
      "Epoch 149/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7397 - loss: 0.5021\n",
      "Epoch 150/150\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.4965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x190311a4190>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.4988\n",
      "Model accuracy: 77.60%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x, y) \n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\DL\\A1.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/DL/A1.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predicted_probabilities \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_probabilities = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values: [1. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "Predicted probabilities: [[0.69942653]\n",
      " [0.12505758]\n",
      " [0.87677544]\n",
      " [0.15481779]\n",
      " [0.80574465]\n",
      " [0.30132717]\n",
      " [0.24059689]\n",
      " [0.6681254 ]\n",
      " [0.9936494 ]\n",
      " [0.0555345 ]]\n",
      "Predicted classes: [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = (predicted_probabilities > 0.5).astype(int)\n",
    "# Print the first 10 actual and predicted values \n",
    "print(\"Actual values:\", y[:10])\n",
    "print(\"Predicted probabilities:\", predicted_probabilities[:10]) \n",
    "print(\"Predicted classes:\", predicted_classes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
